## ROC - анализ

Представим себе, что у нас есть 2 неких условных класса: А и В, или здоровые и больные, или 0 и 1. Более того, представим себе что принадлежность к классу довольно объективна. Например, наличие/отсутствие тромбоза глубоких вен голени. 

У нас есть группа пациентов, которых мы пытаемся разделить на группы в зависимости от принадлежноси к классу. 

Когда мы всесторонне обследуем пациентов и находим тромбоз - пациент попадает в класс 1. Если тромбоза нет, пациент попадает в класс 0. 

Далее представим, что мы придумали новый скрининговый метод, позволяющий за 10 секунд с помощью смартфона выяить наличие/отсутствие тромбоза у пациента. 

Нам нужно подтвердить, что наш метод является:

- работает (способен хоть как-то отличить здоровых от больных);
- работает неплохо (демонстрирует низкое количество ложноположительных и ложноотрицательных результатов)

Наша задача - протестировать, как новый метод справляется с классификацией. Для этого мы проверяем, насколько хорошо метод диагностирует тромбоз (дает истинноположительный результат) и насколько хорошо он исключает тромбоз у пациентов при его отсутствии (истинноотрицательный результат). 

В итоге, мы можем составить вот такую таблицу сопряженности, которая получила название матрица ошибок или *confusion matrix/ error matrix*. 

|                         | Предсказанные значения 1           | Предсказанные значения 0            |
| ----------------------- | ---------------------------------- | ----------------------------------- |
| **Реальные значения 1** | Истинноположительные значения (TP) | Ложноотрицательные значения (FN)    |
| **Реальные значения 0** | Ложноположительные значения (FP)   | Истинно отрицательные значения (TN) |

Если новый тест хорошо справляется и с задачей подтверждения диагноза, и с задачей исключения диагноза, значения TP и TN будут высокими, а FP и FN - низкими. Такие тесты практически идеальны. 

Если тест хорошо подтверждает диагноз, но плохо исключает, то высокими будут значения TP и FN, а низкими - TN и FP.

Тесты, которые хорошо исключают диагноз, но плохо подтверждают, имеют высокие показатели TN и FP, и низкие TP и FN.

С матрицей ошибок связан целый ряд параметров, которые мы можем узнать о новом тесте:


- Чувствительность (sensitivity, recall, true positive rate (TPR)):

$TPR = \frac {\mathrm{TP}} {\mathrm{TP}+\mathrm{FN}}= 1 - \mathrm{FNR}$

- Специфичность (specificity, selectivity, true negative rate (TNR)):

$TNR = \frac {\mathrm{TN}} {\mathrm{TN} + \mathrm{FP}} = 1 - \mathrm{FPR}$

- Положительная прогностическая ценность (precision, positive predictive value):

$PPV = \frac {\mathrm{TP}} {\mathrm{TP} + \mathrm{FP}} = 1 - \mathrm{FDR}$

- Отрицательная прогностическая ценность (negative predictive value): 

$NPV = \frac {\mathrm{TN}} {\mathrm{TN} + \mathrm{FN}} = 1 - \mathrm{FOR}$

- Частота ложноотрицательных значений (false negative rate):

$FNR = \frac {\mathrm{FN}} {\mathrm{FN} + \mathrm{TP}} = 1 - \mathrm{TPR}$

- Частота ложноположительных значений (false positive rate): 

$FPR = \frac {\mathrm{FP}} {\mathrm{FP} + \mathrm{TN}} = 1 - \mathrm{TNR}$

- false discovery rate (FDR): 

$FDR = \frac {\mathrm{FP}} {\mathrm{FP} + \mathrm{TP}} = 1 - \mathrm{PPV}$

- false omission rate (FOR): 

$FOR = \frac {\mathrm{FN}} {\mathrm{FN} + \mathrm{TN}} = 1 - \mathrm{NPV}$

- Положительное отношение правдоподобия (positive likelihood ratio (LR+)): 

$LR+ = \frac {\mathrm{TPR}} {\mathrm{FPR}}$

- Отрицательное отношение правдоподобия (negative likelihood ratio (LR-)): 

$LR- = \frac {\mathrm{FNR}} {\mathrm{TNR}}$

- Точность (accuracy): 

$ACC = \frac {\mathrm{TP} + \mathrm{TN}} {\mathrm{TP} + \mathrm{TN} + \mathrm{FP} + \mathrm{FN}}$

- скорректированная точность (balanced accuracy (BA)): 

$BA = \frac {TPR + TNR}{2}$

- F1 score - гармоническое среднее между PPV и TPR: 

$F_1 = 2 \times \frac {\mathrm{PPV} \times \mathrm{TPR}} {\mathrm{PPV} + \mathrm{TPR}} = \frac {2 \mathrm{TP}} {2 \mathrm{TP} + \mathrm{FP} + \mathrm{FN}}$

- Коэффициент корреляции Мэтью (Matthews correlation coefficient (MCC)): 

$MCC = \frac{ \mathrm{TP} \times \mathrm{TN} - \mathrm{FP} \times \mathrm{FN} } {\sqrt{ (\mathrm{TP}+\mathrm{FP}) ( \mathrm{TP} + \mathrm{FN} ) ( \mathrm{TN} + \mathrm{FP} ) ( \mathrm{TN} + \mathrm{FN} ) }}$

Данные показатели мы часто используем для:

- оценки качеств диагностического теста при объективной принадлежности к классам (как в условиях выше);

- оценки качеств нового диагностичексого теста по отношению к "золотому стандарту" (при этом мы принимаем гипотезу о том, что "золотой стандарт" является объективным классификатором).

## ROC-кривая для бинарного классификатора

Для того, чтобы построить ROC-кривую, нам нужны значения FPR и TPR. 
ROC - кривая представляет собой график зависимости между FPR и TPR. 

В самом простом случае, как в том, что мы описали ранее, объективных реальных классов два: 0 и 1, предсказанных классов тоже два, также со значениями 0 и 1. 
То есть, у нас есть 2 класса с реальными значениями $\{0,1,1,0,1,1,0,0,0,1,0,1,0,1\}$ и соответствующие им предсказанные новым тестом значения $\{0,0,0,0,1,0,1,1,1,1,1,1,1,1\}$. Мы строим матрицу ошибок и у нас будет одно рассчитанное значение FPR и соответствующее ему значение TPR. На нешем графике будет всего одна точка, мы отмечаем ее, соединяем кривую и получаем следующий график:

![ROC_one](https://i.stack.imgur.com/tILQS.png)

## ROC-кривая для вещественных признаков

Представим более сложную ситуацию. У нас есть 2 класса с реальными значениями $\{0,1,1,0,1,1,0,0,0,1,0,1,0,1\}$, и им соответствует вещественный (непрерывный числовой) признак со значениями $\{0,1,1,2,3,1,4,5,4,6,7,8,6,9\}$. 

В такой ситуации мы: 

- выстраиваем значения нашего вещественного признака по возрастанию $\{0,1,2,3,4,5,6,7,8,9\}$; 
- каждое значение вещественного признака становится *порогом*,
- из каждого значения вещественного признака мы создаем новую бинарную переменную так, что значения ниже или равные порогу являются классом 0, а выше порога - классом 1:

    - для значения 0 все нули становятся 0, а остальные значения 1:

    $\{0,1,1,1,1,1,1,1,1,1,1,1,1,1\}$

    - для значения 1 все нули и 1 становятся 0, а остальные значения 1:

    $\{0,0,0,1,1,0,1,1,1,1,1,1,1,1\}$

    - для значения 2 все 0, 1 и 2 становятся 0, а остальные значения 1:

    $\{0,0,0,0,1,0,1,1,1,1,1,1,1,1\}$

    - и т.д.

- каждую такую бинарную переменную мы соотносим с реальными значениями классов $\{0,1,1,0,1,1,0,0,0,1,0,1,0,1\}$ и рассчитываем FPR и TPR, которые и отмечаем на графике;

- соединив точки, мы получаем следующий график:

![ROC_many](https://scikit-learn.org/stable/_images/sphx_glr_plot_roc_001.png)
